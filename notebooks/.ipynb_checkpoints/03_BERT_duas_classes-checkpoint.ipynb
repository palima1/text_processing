{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea225d7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tf2' from 'tensorflow.python' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1752/1773289381.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Modelagem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\rsd_texto\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'tf2' from 'tensorflow.python' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Manipulação dos dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Segmentação dos dados\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelagem\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM,Dense,Bidirectional,Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import transformers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d3f5c",
   "metadata": {},
   "source": [
    "# Importação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6783b4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1752/3686535465.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..\\datasets\\mouse_ajust.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('..\\datasets\\mouse_ajust.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e91b03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>score</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O produto aparece usado...em baixo do aparelho...</td>\n",
       "      <td>13 de novembro de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Mouse sem fio ótimo, sem delay, nano receptor ...</td>\n",
       "      <td>19 de agosto de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A construção do mouse em si é boa, os clicks s...</td>\n",
       "      <td>15 de março de 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>A mídia não pôde ser carregada.\\r\\n           ...</td>\n",
       "      <td>31 de julho de 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>O mouse está em boas condições, funcionando be...</td>\n",
       "      <td>21 de junho de 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  score                                        description  \\\n",
       "0           0      0  O produto aparece usado...em baixo do aparelho...   \n",
       "1           1      2  Mouse sem fio ótimo, sem delay, nano receptor ...   \n",
       "2           2      1  A construção do mouse em si é boa, os clicks s...   \n",
       "3           3      2  A mídia não pôde ser carregada.\\r\\n           ...   \n",
       "4           4      0  O mouse está em boas condições, funcionando be...   \n",
       "\n",
       "                     date  \n",
       "0  13 de novembro de 2019  \n",
       "1    19 de agosto de 2019  \n",
       "2     15 de março de 2019  \n",
       "3     31 de julho de 2020  \n",
       "4     21 de junho de 2020  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "472cae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção de uma classe\n",
    "df['score'].replace({1:0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "616320b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'].replace({2:1},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ae0c3",
   "metadata": {},
   "source": [
    "# Train-test-split [Desbalanceado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c4d62dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['score']\n",
    "x = df.iloc[:,1]\n",
    "\n",
    "#divisão do treino e teste\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f768e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balanceamento \n",
    "\n",
    "'''ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(np.array(X_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1))\n",
    "\n",
    "print(X_resampled.shape)\n",
    "print(y_resampled.shape)\n",
    "print('\\n',pd.DataFrame(y_resampled).value_counts())\n",
    "\n",
    "X_train , y_train = pd.DataFrame(X_resampled), y_resampled\n",
    "\n",
    "X_train = np.array(X_train[0])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ada3cf",
   "metadata": {},
   "source": [
    "# BERT com modelo pré-treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576e702",
   "metadata": {},
   "source": [
    "- Carregando o tokenizador pré-treinado pt-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac2c269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the real tokenizer\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased' , lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8391957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the loaded tokenizer locally\n",
    "tokenizer.save_pretrained('.')\n",
    "# Reload it with the huggingface tokenizers library\n",
    "fast_tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase=True)\n",
    "fast_tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a039d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=400):\n",
    "\n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    tokenizer.enable_padding(length=maxlen)\n",
    "    all_ids = []\n",
    "    \n",
    "    for i in range(0, len(texts), chunk_size):\n",
    "        text_chunk = texts[i:i+chunk_size].tolist()\n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "    \n",
    "    return np.array(all_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9cb2e4",
   "metadata": {},
   "source": [
    "- Tokenizando test e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "16c81003",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fast_encode(X_train.values, fast_tokenizer, maxlen=400)\n",
    "X_test = fast_encode(X_test.values, fast_tokenizer, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "11f17d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840, 400)\n",
      "(960, 400)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cdea69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFDistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b277d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adaf1d387f84e7baec904ef07980f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased',from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e7c991fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e115133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.compile(optimizer='adam', loss = loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b07baaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108923136 \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,924,674\n",
      "Trainable params: 108,924,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ee24e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 6215s 16s/step - loss: 0.2535 - accuracy: 0.9378 - val_loss: 0.2363 - val_accuracy: 0.9458\n"
     ]
    }
   ],
   "source": [
    "history = bert_model.fit(X_train,y_train,batch_size = 10 ,validation_data=(X_test,y_test),epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "220494a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 177s 6s/step - loss: 0.7427 - accuracy: 0.9719\n",
      "Accuracy of the model on Testing Data is -  97.1875011920929 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "35015966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/bert_modelo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/bert_modelo\\assets\n"
     ]
    }
   ],
   "source": [
    "# Salvando o modelo\n",
    "\n",
    "export_dir='../models/bert_modelo'\n",
    "tf.saved_model.save(bert_model, export_dir=export_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
